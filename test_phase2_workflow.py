#!/usr/bin/env python3
"""
Test Phase 2 Plan and Create Workflow

This test file mocks agent responses to test the complete Plan and Create workflow
without requiring actual model calls.
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock
from typing import Dict, Any

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from utils.agent_messages import (
    ProjectInfo, AgentMessage, MessageType, ProjectPlan, Phase, 
    ProjectFiles, FileContent, create_plan_response
)
from utils.workflow_state import WorkflowState
from orchestrator import WorkflowOrchestrator
from agents.planner_agent import PlannerAgent
from agents.writer_agent import WriterAgent
from agents.reviewer_agent import ReviewerAgent
from utils.logger import setup_logger, get_logger


class MockModelClient:
    """Mock model client for testing."""
    
    def __init__(self, responses: Dict[str, str] = None):
        self.responses = responses or {}
        self.call_count = 0
    
    async def create(self, messages):
        """Mock model call."""
        self.call_count += 1
        
        # Get user message content
        user_content = ""
        for msg in messages:
            if hasattr(msg, 'source') and msg.source == 'user':
                user_content = msg.content
                break
        
        # Return appropriate mock response based on content
        if "success criterion" in user_content.lower():
            # Reviewer evaluation
            return MockResponse("RESULT: PASS - All requirements met successfully")
        elif "generate" in user_content.lower() and "file" in user_content.lower():
            # Writer code generation
            filename = self._extract_filename(user_content)
            return MockResponse(self._generate_mock_code(filename))
        elif "project plan" in user_content.lower():
            # Planner response
            return MockResponse(self._generate_mock_plan())
        else:
            # Default response
            return MockResponse("# Mock code generated successfully\nprint('Hello, World!')")
    
    def _extract_filename(self, content: str) -> str:
        """Extract filename from content."""
        lines = content.split('\n')
        for line in lines:
            if "Generate the file" in line and "'" in line:
                parts = line.split("'")
                if len(parts) >= 2:
                    return parts[1]
        return "main.py"
    
    def _generate_mock_code(self, filename: str) -> str:
        """Generate mock code based on filename."""
        if filename.endswith('.py'):
            if 'main' in filename:
                return '''#!/usr/bin/env python3
"""
Main application entry point.
Generated by LazyToCode Phase 2 test.
"""

def main():
    """Main function."""
    print("Hello from LazyToCode!")
    print("This is a mock generated application.")
    
    # Example functionality
    result = calculate_example()
    print(f"Calculation result: {result}")

def calculate_example():
    """Example calculation function."""
    return 42 * 2

if __name__ == "__main__":
    main()
'''
            elif 'requirements' in filename:
                return '''# Requirements for LazyToCode test project
click>=8.0.0
requests>=2.25.0
pydantic>=1.8.0
'''
            elif 'config' in filename:
                return '''"""
Configuration module for the application.
"""

class Config:
    """Application configuration."""
    
    def __init__(self):
        self.debug = False
        self.version = "1.0.0"
        self.name = "LazyToCode Test App"
    
    def get_settings(self):
        """Get configuration settings."""
        return {
            "debug": self.debug,
            "version": self.version,
            "name": self.name
        }

# Global configuration instance
config = Config()
'''
        elif filename.endswith('.json'):
            return '''{
    "name": "lazytocode-test",
    "version": "1.0.0",
    "description": "Test project generated by LazyToCode",
    "main": "main.py",
    "author": "LazyToCode Agent"
}'''
        elif filename.endswith('.md'):
            return '''# LazyToCode Test Project

This project was generated by the LazyToCode Phase 2 testing workflow.

## Features

- Example main application
- Configuration management
- Basic project structure

## Usage

```bash
python main.py
```

## Requirements

See requirements.txt for dependencies.
'''
        else:
            return f"# Mock content for {filename}\n# Generated by LazyToCode test\n"
    
    def _generate_mock_plan(self) -> str:
        """Generate mock project plan."""
        return '''Based on the requirements, I'll create a simple Python CLI application with the following structure:

**Phase 1: Project Setup**
- Create basic project structure
- Set up configuration files
- Create main entry point

**Phase 2: Core Implementation**  
- Implement main application logic
- Add configuration management
- Create documentation

This plan will create a functional CLI application following Python best practices.
'''


class MockResponse:
    """Mock response object."""
    
    def __init__(self, content: str):
        self.content = content
        self.finish_reason = "completed"


class TestWorkflowManager:
    """Manages the test workflow execution."""
    
    def __init__(self, debug: bool = True):
        self.debug = debug
        self.logger = None
        self.output_dir = Path("test_output_phase2")
        
    async def setup(self):
        """Setup test environment."""
        # Setup logging
        self.logger = setup_logger(
            debug_mode=self.debug,
            log_file="test_phase2_workflow.log" if self.debug else None
        )
        
        # Create output directory
        self.output_dir.mkdir(exist_ok=True)
        
        self.logger.info("Test environment setup complete")
    
    async def create_test_plan_json(self) -> Path:
        """Create a mock plan JSON file for testing."""
        plan_data = {
            "project_info": {
                "prompt": "Create a simple Python CLI application that greets users",
                "project_type": "python_cli",
                "language": "python",
                "output_dir": str(self.output_dir)
            },
            "phases": [
                {
                    "phase_id": "phase_1",
                    "name": "Project Setup",
                    "description": "Create basic project structure and configuration",
                    "files_to_create": [
                        "main.py",
                        "requirements.txt",
                        "README.md"
                    ],
                    "dependencies": [],
                    "estimated_complexity": 2,
                    "success_criteria": [
                        "All required files are created",
                        "main.py contains a working main() function",
                        "requirements.txt lists necessary dependencies",
                        "README.md provides project documentation"
                    ]
                },
                {
                    "phase_id": "phase_2", 
                    "name": "Core Implementation",
                    "description": "Implement core application logic and features",
                    "files_to_create": [
                        "config.py",
                        "package.json"
                    ],
                    "dependencies": ["click"],
                    "estimated_complexity": 3,
                    "success_criteria": [
                        "config.py provides configuration management",
                        "package.json contains project metadata",
                        "All files integrate properly"
                    ]
                }
            ],
            "total_phases": 2,
            "estimated_duration": 30
        }
        
        plan_file = self.output_dir / f"plan_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan_data, f, indent=2)
        
        self.logger.info(f"Created test plan JSON: {plan_file}")
        return plan_file
    
    async def run_workflow_test(self, test_scenario: str = "success") -> Dict[str, Any]:
        """Run the complete workflow test."""
        
        try:
            self.logger.info(f"Running workflow test scenario: {test_scenario}")
            
            # Create test plan
            plan_file = await self.create_test_plan_json()
            
            # Create project info
            project_info = ProjectInfo(
                prompt="Create a simple Python CLI application that greets users",
                project_type="python_cli",
                language="python",
                output_dir=str(self.output_dir)
            )
            
            # Create mock model client
            mock_client = MockModelClient()
            
            # Create agents with mocked model client
            planner = PlannerAgent(
                name="TestPlanner",
                model_client=mock_client,
                output_dir=self.output_dir
            )
            
            writer = WriterAgent(
                name="TestWriter", 
                model_client=mock_client,
                output_dir=self.output_dir
            )
            
            reviewer = ReviewerAgent(
                name="TestReviewer",
                model_client=mock_client if test_scenario != "no_model" else None,
                output_dir=self.output_dir
            )
            
            # Create orchestrator
            max_attempts = 2 if test_scenario == "retry" else 3
            orchestrator = WorkflowOrchestrator(
                project_info=project_info,
                max_attempts=max_attempts
            )
            
            # Register agents
            orchestrator.register_agent("planner", planner)
            orchestrator.register_agent("writer", writer)
            orchestrator.register_agent("reviewer", reviewer)
            
            # Mock the planner response to use our test plan
            original_handle = planner.handle_message
            
            async def mock_planner_response(message, ctx=None):
                if message.message_type == MessageType.PLAN_REQUEST:
                    # Load our test plan and convert to ProjectPlan object
                    with open(plan_file, 'r') as f:
                        plan_data = json.load(f)
                    
                    # Convert to proper objects
                    from utils.agent_messages import ProjectPlan, Phase, ProjectInfo
                    
                    project_info_data = plan_data["project_info"]
                    project_info = ProjectInfo(**project_info_data)
                    
                    phases = []
                    for phase_data in plan_data["phases"]:
                        phase = Phase(
                            phase_id=phase_data["phase_id"],
                            name=phase_data["name"],
                            description=phase_data["description"],
                            files_to_create=phase_data.get("files_to_create", []),
                            dependencies=phase_data.get("dependencies", []),
                            estimated_complexity=phase_data.get("estimated_complexity", 3),
                            prerequisites=phase_data.get("prerequisites", [])
                        )
                        phases.append(phase)
                    
                    project_plan = ProjectPlan(
                        project_info=project_info,
                        phases=phases,
                        total_phases=plan_data.get("total_phases", len(phases)),
                        estimated_duration=plan_data.get("estimated_duration", 60)
                    )
                    
                    response = create_plan_response(
                        sender="TestPlanner",
                        recipient=message.sender,
                        project_plan=project_plan,
                        phase_id=message.phase_id,
                        correlation_id=message.correlation_id
                    )
                    
                    return response
                else:
                    return await original_handle(message, ctx)
            
            planner.handle_message = mock_planner_response
            
            # Modify reviewer behavior based on test scenario
            if test_scenario == "review_failure":
                original_review = reviewer.review_phase_completion
                
                async def mock_failing_review(*args, **kwargs):
                    attempt = kwargs.get('attempt_number', 1)
                    if attempt <= 2:  # Fail first 2 attempts
                        return False, "Mock review failure: Files do not meet requirements"
                    else:
                        return True, None
                
                reviewer.review_phase_completion = mock_failing_review
            
            # Execute workflow
            self.logger.info("Starting workflow execution...")
            result = await orchestrator.execute_workflow()
            
            # Collect results
            test_result = {
                "scenario": test_scenario,
                "success": result.get("success", False),
                "error": result.get("error"),
                "summary": result.get("summary", {}),
                "generated_files": result.get("generated_files", []),
                "plan_file": str(plan_file),
                "output_directory": str(self.output_dir),
                "model_calls": mock_client.call_count
            }
            
            # Cleanup
            await orchestrator.cleanup()
            
            return test_result
            
        except Exception as e:
            self.logger.error(f"Workflow test failed: {str(e)}")
            return {
                "scenario": test_scenario,
                "success": False,
                "error": str(e),
                "model_calls": getattr(mock_client, 'call_count', 0) if 'mock_client' in locals() else 0
            }
    
    def print_results(self, results: Dict[str, Any]):
        """Print test results in a formatted way."""
        
        print(f"\n{'='*60}")
        print(f"Phase 2 Workflow Test Results - {results['scenario'].upper()}")
        print(f"{'='*60}")
        
        if results['success']:
            print("✅ WORKFLOW SUCCESS")
        else:
            print("❌ WORKFLOW FAILED")
            if results.get('error'):
                print(f"Error: {results['error']}")
        
        print(f"\nTest Details:")
        print(f"  Scenario: {results['scenario']}")
        print(f"  Model Calls: {results.get('model_calls', 0)}")
        print(f"  Output Directory: {results.get('output_directory', 'N/A')}")
        
        if results.get('generated_files'):
            print(f"\nGenerated Files ({len(results['generated_files'])}):")
            for file_info in results['generated_files']:
                print(f"  📄 {file_info['filename']} ({file_info['language']})")
        
        if results.get('plan_file'):
            print(f"\nPlan File: {results['plan_file']}")
        
        # Show workflow summary if available
        summary = results.get('summary', {})
        if summary:
            print(f"\nWorkflow Summary:")
            print(f"  Status: {summary.get('status', 'Unknown')}")
            print(f"  Duration: {summary.get('duration', 'Unknown')}")
            print(f"  Phases: {summary.get('total_phases', 0)}")
            print(f"  Completed: {summary.get('completed_phases', 0)}")
    
    async def cleanup(self):
        """Cleanup test environment."""
        self.logger.info("Test cleanup complete")


async def run_all_tests():
    """Run all test scenarios."""
    
    test_manager = TestWorkflowManager(debug=True)
    await test_manager.setup()
    
    test_scenarios = [
        "success",           # Normal successful workflow
        "review_failure",    # Review fails initially but succeeds on retry
        "no_model"          # Test with no model client (basic evaluation)
    ]
    
    all_results = []
    
    print("🧪 Starting Phase 2 Workflow Tests...")
    print(f"Running {len(test_scenarios)} test scenarios\n")
    
    for scenario in test_scenarios:
        print(f"🔄 Running test scenario: {scenario}")
        
        try:
            result = await test_manager.run_workflow_test(scenario)
            all_results.append(result)
            test_manager.print_results(result)
            
        except Exception as e:
            print(f"❌ Test scenario {scenario} failed with error: {str(e)}")
            all_results.append({
                "scenario": scenario,
                "success": False,
                "error": str(e)
            })
        
        print(f"\n{'-'*60}\n")
    
    # Print overall summary
    print(f"{'='*60}")
    print("OVERALL TEST SUMMARY")
    print(f"{'='*60}")
    
    passed = sum(1 for r in all_results if r['success'])
    total = len(all_results)
    
    print(f"Tests Passed: {passed}/{total}")
    
    for result in all_results:
        status = "✅ PASS" if result['success'] else "❌ FAIL"
        print(f"  {status} - {result['scenario']}")
    
    await test_manager.cleanup()
    
    return passed == total


if __name__ == "__main__":
    try:
        success = asyncio.run(run_all_tests())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n🛑 Tests cancelled by user")
        sys.exit(130)
    except Exception as e:
        print(f"❌ Test execution failed: {e}")
        sys.exit(1)